{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module: main_TSC_LS.ipynb\n",
    "Author: Dema N. Govalla\n",
    "Date: December 4, 2023\n",
    "Description: The file trains and test the combined_sensorData.csv file using the RFMN algorithm. \n",
    "            After traning and testing, it returns the algorithms metrics such as accuracy, presision and more.\n",
    "            The file performs cross validation for different RFMN parameters and returns the classification\n",
    "            report.  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np, pandas as pd, os, multiprocessing, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from RFMN import ReflexFuzzyNeuroNetwork\n",
    "from time import time\n",
    "import warnings\n",
    "import matplotlib, shutil\n",
    "warnings.filterwarnings(\"ignore\", category=matplotlib.MatplotlibDeprecationWarning)\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_test, y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='micro')\n",
    "    recall = recall_score(y_test, y_pred, average='micro')\n",
    "    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report_def = classification_report(y_test, y_pred)\n",
    "    return mae, mse, rmse, r2, accuracy, precision, recall, f1, conf_matrix, class_report_def\n",
    "\n",
    "def plot_accuracy_bar_graph(values_array, plot_title, save_filename):\n",
    "    directory_path_result = 'RFMN_result'\n",
    "    if not os.path.exists(directory_path_result):\n",
    "        os.makedirs(directory_path_result)\n",
    "        \n",
    "    num_gammas = len(values_array[0])\n",
    "    num_thetas = len(values_array)\n",
    "\n",
    "    bar_width = 0.06\n",
    "    index = np.arange(num_gammas)\n",
    "    colors = plt.cm.get_cmap('tab10', num_thetas)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(num_thetas):\n",
    "        bars = plt.bar(index + i * bar_width, values_array[i], width=bar_width, label=f'Theta = {0.1 + i * 0.1}', color=colors(i))\n",
    "        for bar, acc in zip(bars, values_array[i]):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{acc:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "    plt.xlabel('Gamma')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(plot_title)\n",
    "    plt.xticks(index + (bar_width * (num_thetas - 1)) / 2, [f'Gamma {i+1}' for i in range(num_gammas)])  # Custom x-ticks for gammas\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Position the legend outside the plot\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(directory_path_result+ '/' + save_filename)  # Save as PNG file\n",
    "\n",
    "\n",
    "def average_of_n_values(arr):\n",
    "    if not arr:\n",
    "        return \"Input array is empty. Please provide values.\"\n",
    "    return (sum(arr) / len(arr))*100\n",
    "\n",
    "def convert_seconds_to_minutes(seconds):\n",
    "    minutes = seconds // 60\n",
    "    remaining_seconds = seconds % 60\n",
    "    result = f\"{minutes} minute{'s' if minutes != 1 else ''}\"\n",
    "    if remaining_seconds > 0:\n",
    "        result += f\" and {remaining_seconds} second{'s' if remaining_seconds != 1 else ''}\"\n",
    "    return result\n",
    "\n",
    "def testAlgo(X_test, y_test, nn, y_predlr): \n",
    "    y_predlr1 = nn.test(X_test, y_test)\n",
    "    y_predlr.send(y_predlr1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in the system: 12\n"
     ]
    }
   ],
   "source": [
    "print('Number of CPUs in the system: {}'.format(os.cpu_count()))\n",
    "\n",
    "sensor_data = pd.read_csv('combined_sensorData_def.csv')\n",
    "sensor_data = sensor_data.iloc[:,0:]\n",
    "\n",
    "# separate the independent and dependent features\n",
    "X_def = sensor_data.iloc[:, np.r_[0:4, 8]]\n",
    "y_def = sensor_data.iloc[:, sensor_data.shape[1]-1]\n",
    "\n",
    "# separate the independent and dependent features\n",
    "X_tex = sensor_data.iloc[:, np.r_[2:9]] \n",
    "y_tex = sensor_data.iloc[:, sensor_data.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File count: 40\n"
     ]
    }
   ],
   "source": [
    "directory_path_param = 'cross_val_RFMN_param'\n",
    "\n",
    "if os.path.exists(directory_path_param):\n",
    "    shutil.rmtree(directory_path_param)\n",
    "    os.makedirs(directory_path_param)\n",
    "    \n",
    "else:\n",
    "    os.makedirs(directory_path_param)\n",
    "    \n",
    "\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle= True, random_state=42)\n",
    "\n",
    "fold_no_def = 1\n",
    "for train_index_def, val_index_def in skf.split(X_def, y_def):\n",
    "    train_def = X_def.loc[train_index_def,:]\n",
    "    val_def = X_def.loc[val_index_def,:]\n",
    "    train_def.to_csv(os.path.join(directory_path_param, 'train_fold_def_' + str(fold_no_def) + '.csv'))\n",
    "    val_def.to_csv(os.path.join(directory_path_param, 'val_fold_def_' + str(fold_no_def) + '.csv'))\n",
    "    fold_no_def += 1\n",
    "\n",
    "fold_no_tex = 1\n",
    "for train_index_tex, val_index_tex in skf.split(X_tex, y_tex):\n",
    "    train_tex = X_tex.loc[train_index_tex,:]\n",
    "    val_tex = X_tex.loc[val_index_tex,:]\n",
    "    train_tex.to_csv(os.path.join(directory_path_param, 'train_fold_tex_' + str(fold_no_tex) + '.csv'))\n",
    "    val_tex.to_csv(os.path.join(directory_path_param, 'val_fold_tex_' + str(fold_no_tex) + '.csv'))\n",
    "    fold_no_tex += 1\n",
    "\n",
    "count = 0\n",
    "for path in os.listdir(directory_path_param):\n",
    "    if os.path.isfile(os.path.join(directory_path_param, path)):\n",
    "        count += 1\n",
    "print('File count:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_values = [1, 2]  \n",
    "gamma_values = [1, 2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "k-fold parameters for deformation\n",
    "'''\n",
    "k_fold_mae_def = []\n",
    "k_fold_mse_def = []\n",
    "k_fold_rmse_def = []\n",
    "k_fold_r2_def = []\n",
    "\n",
    "k_fold_accuracy_def = []\n",
    "k_fold_precision_def = []\n",
    "k_fold_recall_def = []\n",
    "k_fold_f1_def = []\n",
    "\n",
    "'''\n",
    "k-fold parameters for texture\n",
    "'''\n",
    "k_fold_mae_tex = []\n",
    "k_fold_mse_tex = []\n",
    "k_fold_rmse_tex = []\n",
    "k_fold_r2_tex = []\n",
    "\n",
    "k_fold_accuracy_tex = []\n",
    "k_fold_precision_tex = []\n",
    "k_fold_recall_tex = []\n",
    "k_fold_f1_tex = []\n",
    "\n",
    "'''\n",
    "Metric value arrays for deformation\n",
    "'''\n",
    "mae_values_array_def = []\n",
    "mse_values_array_def = []\n",
    "rmse_values_array_def = []\n",
    "r2_values_array_def = []\n",
    "\n",
    "accuracy_values_array_def = []\n",
    "precision_values_array_def = []\n",
    "recall_values_array_def = []\n",
    "f1_values_array_def = []\n",
    "\n",
    "'''\n",
    "Metric value arrays for texture\n",
    "'''\n",
    "mae_values_array_tex = []\n",
    "mse_values_array_tex = []\n",
    "rmse_values_array_tex = []\n",
    "r2_values_array_tex = []\n",
    "\n",
    "accuracy_values_array_tex = []\n",
    "precision_values_array_tex = []\n",
    "recall_values_array_tex = []\n",
    "f1_values_array_tex = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is Done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Full Deformation code for RFMN\n",
    "'''\n",
    "startTime4 = time()\n",
    "\n",
    "for theta in theta_values:\n",
    "    \n",
    "    '''\n",
    "    Metric value for deformation\n",
    "    '''\n",
    "    mae_values_def = []\n",
    "    mse_values_def = []\n",
    "    rmse_values_def = []\n",
    "    r2_values_def = []\n",
    "    \n",
    "    accuracy_values_def = []\n",
    "    precision_values_def = []\n",
    "    recall_values_def = []\n",
    "    f1_values_def = []\n",
    "    \n",
    "    for gamma in gamma_values:\n",
    "        \n",
    "        startTime3 = time() # Add a timer. \n",
    "        \n",
    "        '''\n",
    "        Metric ave for deformation\n",
    "        '''\n",
    "        mae_ave_def = []\n",
    "        mse_ave_def = []\n",
    "        rmse_ave_def = []\n",
    "        r2_ave_def = []\n",
    "        \n",
    "        accuracy_ave_def = []\n",
    "        precision_ave_def = []\n",
    "        recall_ave_def = []\n",
    "        f1_ave_def = []\n",
    "    \n",
    "        \n",
    "        for fold_no in range(1,n_splits+1):\n",
    "            \n",
    "            startTime2 = time() # Add a timer. \n",
    "            scaler_min_max = MinMaxScaler(feature_range=(0.01, .99))\n",
    "            \n",
    "            '''\n",
    "            Train the deformation data\n",
    "            '''\n",
    "            newtrain_def = pd.read_csv(os.path.join(directory_path_param, 'train_fold_def_' + str(fold_no) + '.csv'))\n",
    "            \n",
    "            newtrain_def = newtrain_def.iloc[:,1:]\n",
    "            new_X_train_def = newtrain_def.iloc[:,:-1].values\n",
    "            new_y_train_def = newtrain_def.iloc[:,-1].values # Assign the label to the last column\n",
    "            \n",
    "            new_X_train_def = scaler_min_max.fit_transform(new_X_train_def)\n",
    "            new_X_train_def = new_X_train_def.T\n",
    "\n",
    "            nn_train_def = ReflexFuzzyNeuroNetwork(gamma=gamma, theta=theta*.1)\n",
    "            nn_train_def.train(new_X_train_def, new_y_train_def)\n",
    "            print(\"Training is Done\")\n",
    "\n",
    "            '''\n",
    "            Start the multiprocessing process for testing deformation.\n",
    "            '''\n",
    "            '''\n",
    "            Test the deformation data\n",
    "            '''\n",
    "            newval_def = pd.read_csv(os.path.join(directory_path_param, 'val_fold_def_' + str(fold_no) + '.csv'))\n",
    "            newval_def = newval_def.iloc[:,1:]\n",
    "        \n",
    "            X_def_newval = newval_def.iloc[:, :4].values\n",
    "            y_def_newval = newval_def.iloc[:, newval_def.shape[1]-1].values\n",
    "            \n",
    "            new_X_val_def = scaler_min_max.fit_transform(X_def_newval)\n",
    "\n",
    "            X_train_def, X_test_def, y_train_def, y_test_def_newval = train_test_split(new_X_val_def, y_def_newval, train_size=1, random_state=42)\n",
    "\n",
    "            num_parts_def = 3950\n",
    "            # num_parts_def = 2634\n",
    "            # num_parts_def = 1580\n",
    "            split_size_def = len(X_test_def) // num_parts_def\n",
    "            x_split_def = []\n",
    "            y_split_def = []\n",
    "            for i in range(num_parts_def):\n",
    "                start_index_def = i * split_size_def\n",
    "                end_index_def = (i + 1) * split_size_def\n",
    "                x_part_def = X_test_def[start_index_def:end_index_def]\n",
    "                y_part_def = y_test_def_newval[start_index_def:end_index_def]\n",
    "                x_split_def.append(x_part_def)\n",
    "                y_split_def.append(y_part_def)\n",
    "            x_split_def = np.array(x_split_def)\n",
    "            y_split_def = np.array(y_split_def)\n",
    "\n",
    "            transposed_arrays_def = []\n",
    "            for i in range(num_parts_def):\n",
    "                transposed_arrays_def.append(x_split_def[i].T)\n",
    "            transposed_arrays_def = np.array(transposed_arrays_def)\n",
    "\n",
    "\n",
    "            '''\n",
    "            Get the accuracy for defromation and texture\n",
    "            '''\n",
    "            end_range = 10\n",
    "            \n",
    "            y_test_def = np.array([])\n",
    "            jobs_def = []\n",
    "            pipe_list_def = []\n",
    "\n",
    "\n",
    "            # for i in range(0, os.cpu_count()):\n",
    "            # for i in range(0, 94):\n",
    "            for i in range(0, end_range):\n",
    "                startTime1 = time() # Add a timer. \n",
    "    \n",
    "                # range(0, os.cpu_count())\n",
    "                recv_end_def, send_end_def = multiprocessing.Pipe(False)\n",
    "                p_def = multiprocessing.Process(target=testAlgo, args=(transposed_arrays_def[i], y_split_def[i], nn_train_def, send_end_def))\n",
    "            \n",
    "                jobs_def.append(p_def)\n",
    "                pipe_list_def.append(recv_end_def)\n",
    "                p_def.start()\n",
    "\n",
    "            # Create a new numpy array the same as y_split_def\n",
    "            for i in range(end_range): \n",
    "                new_elements_def = y_split_def[i]  \n",
    "                y_test_def = np.append(y_test_def, new_elements_def)\n",
    "            y_test_def = y_test_def.reshape((end_range, -1))\n",
    "\n",
    "            # Join all cores results into one\n",
    "            for proc in jobs_def:\n",
    "                proc.join()\n",
    "\n",
    "            '''\n",
    "            Metrics For Deformation\n",
    "            '''\n",
    "            # Putting all cores results into an array    \n",
    "            result_list_def = np.array([x.recv().tolist() for x in pipe_list_def])\n",
    "            y_pred_flat_def = result_list_def.flatten()\n",
    "            y_test_flat_def = y_test_def.flatten()\n",
    "\n",
    "            mae_def, mse_def, rmse_def, r2_def, accuracy_def, precision_def, recall_def, f1_def, conf_matrix_def, class_report_def = calculate_metrics(y_test_flat_def, y_pred_flat_def)\n",
    "            print(\"mae:\", mae_def*100)\n",
    "            print(\"mse:\", mse_def*100)\n",
    "            print(\"rmse:\", rmse_def*100)\n",
    "            print(\"r2:\", r2_def*100)\n",
    "            \n",
    "            print(\"Accuracy:\", accuracy_def*100)\n",
    "            print(\"Precision:\", precision_def*100)\n",
    "            print(\"Recall:\", recall_def*100)\n",
    "            print(\"F1 Score:\", f1_def*100)\n",
    "            print(\"Confusion Matrix:\\n\", conf_matrix_def)\n",
    "            print(\"Classification report:\\n\", class_report_def)\n",
    "            \n",
    "            mae_ave_def.append(mae_def)\n",
    "            mse_ave_def.append(mse_def)\n",
    "            rmse_ave_def.append(rmse_def)\n",
    "            r2_ave_def.append(r2_def)\n",
    "            \n",
    "            accuracy_ave_def.append(accuracy_def)\n",
    "            precision_ave_def.append(precision_def)\n",
    "            recall_ave_def.append(recall_def)\n",
    "            f1_ave_def.append(f1_def)\n",
    "            \n",
    "            print(\"done\")\n",
    "                    \n",
    "        \n",
    "        '''\n",
    "        Combine K-fold for deformation\n",
    "        '''\n",
    "        k_fold_mae_def.append(mae_ave_def)\n",
    "        k_fold_mse_def.append(mse_ave_def)\n",
    "        k_fold_rmse_def.append(rmse_ave_def)\n",
    "        k_fold_r2_def.append(r2_ave_def)\n",
    "        \n",
    "        k_fold_accuracy_def.append(accuracy_ave_def)\n",
    "        k_fold_precision_def.append(precision_ave_def)\n",
    "        k_fold_recall_def.append(recall_ave_def)\n",
    "        k_fold_f1_def.append(f1_ave_def)\n",
    "        \n",
    "        '''\n",
    "        Combine values for deformation\n",
    "        '''\n",
    "        mae_values_def.append(average_of_n_values(mae_ave_def)) \n",
    "        mse_values_def.append(average_of_n_values(mse_ave_def)) \n",
    "        rmse_values_def.append(average_of_n_values(rmse_ave_def)) \n",
    "        r2_values_def.append(average_of_n_values(r2_ave_def)) \n",
    "        \n",
    "        accuracy_values_def.append(average_of_n_values(accuracy_ave_def))  \n",
    "        precision_values_def.append(average_of_n_values(precision_ave_def)) \n",
    "        recall_values_def.append(average_of_n_values(recall_ave_def)) \n",
    "        f1_values_def.append(average_of_n_values(f1_ave_def)) \n",
    "\n",
    "        # end_time2 = time()\n",
    "        # totalTime2 = convert_seconds_to_minutes(end_time2 - startTime2)\n",
    "        # print(\"Total time 2 is: \", totalTime2)\n",
    "\n",
    "    '''\n",
    "    Combine values for deformation\n",
    "    '''\n",
    "    mae_values_array_def.append(mae_values_def)\n",
    "    mse_values_array_def.append(mse_values_def)\n",
    "    rmse_values_array_def.append(rmse_values_def)\n",
    "    r2_values_array_def.append(r2_values_def)\n",
    "    \n",
    "    accuracy_values_array_def.append(accuracy_values_def)\n",
    "    precision_values_array_def.append(precision_values_def)\n",
    "    recall_values_array_def.append(recall_values_def)\n",
    "    f1_values_array_def.append(f1_values_def)\n",
    "    \n",
    "    # end_time3 = time()\n",
    "    # totalTime3 = convert_seconds_to_minutes(end_time3 - startTime3)\n",
    "    # print(\"Total time 3 is: \", totalTime3)\n",
    "\n",
    "'''\n",
    "Print K-fold for deformation\n",
    "'''\n",
    "print(\"These are the def mae for each k-fold split\", k_fold_mae_def, \"\\n\")\n",
    "print(\"These are the def mse for each k-fold split\", k_fold_mse_def, \"\\n\")\n",
    "print(\"These are the def rmse for each k-fold split\", k_fold_rmse_def, \"\\n\")\n",
    "print(\"These are the def r2 for each k-fold split\", k_fold_r2_def, \"\\n\")\n",
    "\n",
    "print(\"These are the def accuracy for each k-fold split\", k_fold_accuracy_def, \"\\n\")\n",
    "print(\"These are the def precision for each k-fold split\", k_fold_precision_def, \"\\n\")\n",
    "print(\"These are the def recall for each k-fold split\", k_fold_recall_def, \"\\n\")\n",
    "print(\"These are the def f1 for each k-fold split\", k_fold_f1_def, \"\\n\")\n",
    "\n",
    "end_time4 = time()\n",
    "totalTime4 = convert_seconds_to_minutes(end_time4 - startTime4)\n",
    "print(\"Total completion time is: \", totalTime4)\n",
    "\n",
    "'''\n",
    "Plot for deformation\n",
    "'''\n",
    "plot_accuracy_bar_graph(mae_values_array_def, \"mae_deformation_plot\", \"mae_deformation_plot\")\n",
    "plot_accuracy_bar_graph(mse_values_array_def, \"mse_deformation_plot\", \"mse_deformation_plot\")\n",
    "plot_accuracy_bar_graph(rmse_values_array_def, \"rmse_deformation_plot\", \"rmse_deformation_plot\")\n",
    "plot_accuracy_bar_graph(r2_values_array_def, \"r2_deformation_plot\", \"r2_deformation_plot\")\n",
    "\n",
    "plot_accuracy_bar_graph(accuracy_values_array_def, \"accuracy_deformation_plot\", \"accuracy_deformation_plot\")\n",
    "plot_accuracy_bar_graph(precision_values_array_def, \"precision_deformation_plot\", \"precision_deformation_plot\")\n",
    "plot_accuracy_bar_graph(recall_values_array_def, \"recall_deformation_plot\", \"recall_deformation_plot\")\n",
    "plot_accuracy_bar_graph(f1_values_array_def, \"f1_deformation_plot\", \"f1_deformation_plot\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Full Texture code for RFMN\n",
    "'''\n",
    "\n",
    "startTime4 = time()\n",
    "\n",
    "for theta in theta_values:\n",
    "    \n",
    "    '''\n",
    "    Metric value for texture\n",
    "    '''\n",
    "    mae_values_tex = []\n",
    "    mse_values_tex = []\n",
    "    rmse_values_tex = []\n",
    "    r2_values_tex = []\n",
    "    \n",
    "    accuracy_values_tex = []\n",
    "    precision_values_tex = []\n",
    "    recall_values_tex = []\n",
    "    f1_values_tex = []\n",
    "    \n",
    "    for gamma in gamma_values:\n",
    "        \n",
    "        startTime3 = time() # Add a timer. \n",
    "    \n",
    "        '''\n",
    "        Metric ave for texture\n",
    "        '''\n",
    "        mae_ave_tex = []\n",
    "        mse_ave_tex = []\n",
    "        rmse_ave_tex = []\n",
    "        r2_ave_tex = []\n",
    "        \n",
    "        accuracy_ave_tex = []\n",
    "        precision_ave_tex = []\n",
    "        recall_ave_tex = []\n",
    "        f1_ave_tex = []\n",
    "        \n",
    "        for fold_no in range(1,n_splits+1):\n",
    "            \n",
    "            startTime2 = time() # Add a timer. \n",
    "            scaler_min_max = MinMaxScaler(feature_range=(0.01, .99))\n",
    "            \n",
    "            '''\n",
    "            Train the texture data\n",
    "            '''\n",
    "            newtrain_tex = pd.read_csv(os.path.join(directory_path_param, 'train_fold_tex_' + str(fold_no) + '.csv'))\n",
    "            \n",
    "            newtrain_tex = newtrain_tex.iloc[:,1:]\n",
    "            new_X_train_tex = newtrain_tex.iloc[:,:-1].values\n",
    "            new_y_train_tex = newtrain_tex.iloc[:,-1].values\n",
    "            \n",
    "            new_X_train_tex = scaler_min_max.fit_transform(new_X_train_tex)\n",
    "            new_X_train_tex = new_X_train_tex.T\n",
    "            \n",
    "            nn_train_tex = ReflexFuzzyNeuroNetwork(gamma=gamma, theta=theta*.1)\n",
    "            nn_train_tex.train(new_X_train_tex, new_y_train_tex)\n",
    "            print(\"Training is Done\")\n",
    "\n",
    "            '''\n",
    "            Start the multiprocessing process for testing deformation.\n",
    "            '''\n",
    "            '''\n",
    "            Test the texture data\n",
    "            '''\n",
    "            newval_tex = pd.read_csv(os.path.join(directory_path_param, 'val_fold_tex_' + str(fold_no) + '.csv'))\n",
    "            newval_tex = newval_tex.iloc[:,1:]\n",
    "            \n",
    "            X_tex_newval = newval_tex.iloc[:, :-1].values\n",
    "            y_tex_newval = newval_tex.iloc[:, newval_tex.shape[1]-1].values\n",
    "            \n",
    "            new_X_val_tex = scaler_min_max.fit_transform(X_tex_newval)\n",
    "\n",
    "            X_train_tex, X_test_tex, y_train_tex, y_test_tex_newval = train_test_split(new_X_val_tex, y_tex_newval, train_size=1, random_state=42)\n",
    "\n",
    "            num_parts_tex = 3950\n",
    "            # num_parts_tex = 2634\n",
    "            # num_parts_tex = 1580\n",
    "            \n",
    "            split_size_tex = len(new_X_val_tex) // num_parts_tex\n",
    "            x_split_tex = []\n",
    "            y_split_tex = []\n",
    "            for i in range(num_parts_tex):\n",
    "                start_index_tex = i * split_size_tex\n",
    "                end_index_tex = (i + 1) * split_size_tex\n",
    "                x_part_tex = X_test_tex[start_index_tex:end_index_tex]\n",
    "                y_part_tex = y_test_tex_newval[start_index_tex:end_index_tex]\n",
    "                x_split_tex.append(x_part_tex)\n",
    "                y_split_tex.append(y_part_tex)\n",
    "            x_split_tex = np.array(x_split_tex)\n",
    "            y_split_tex = np.array(y_split_tex)\n",
    "\n",
    "            transposed_arrays_tex = []\n",
    "            for i in range(num_parts_tex):\n",
    "                transposed_arrays_tex.append(x_split_tex[i].T)\n",
    "            transposed_arrays_tex = np.array(transposed_arrays_tex)\n",
    "\n",
    "            '''\n",
    "            Get the accuracy for defromation and texture\n",
    "            '''\n",
    "            end_range = 10\n",
    "            \n",
    "            y_test_tex = np.array([])\n",
    "            jobs_tex = []\n",
    "            pipe_list_tex = []     \n",
    "\n",
    "            # for i in range(0, os.cpu_count()):\n",
    "            # for i in range(0, 94):\n",
    "            for i in range(0, end_range):\n",
    "                startTime1 = time() # Add a timer. \n",
    "    \n",
    "                # range(0, os.cpu_count())\n",
    "                recv_end_tex, send_end_tex = multiprocessing.Pipe(False)\n",
    "                p_tex = multiprocessing.Process(target=testAlgo, args=(transposed_arrays_tex[i], y_split_tex[i], nn_train_tex, send_end_tex))\n",
    "            \n",
    "    \n",
    "\n",
    "                jobs_tex.append(p_tex)\n",
    "                pipe_list_tex.append(recv_end_tex)\n",
    "                p_tex.start()\n",
    "                \n",
    "            # Create a new numpy array the same as y_split_def\n",
    "            for i in range(end_range): \n",
    "                new_elements_tex = y_split_tex[i]  \n",
    "                y_test_tex = np.append(y_test_tex, new_elements_tex)\n",
    "            y_test_tex = y_test_tex.reshape((end_range, -1))\n",
    "\n",
    "            # Join all cores results into one\n",
    "            for proc in jobs_tex:\n",
    "                proc.join()\n",
    "                    \n",
    "            '''\n",
    "            Metrics For Texture\n",
    "            '''\n",
    "            # Putting all cores results into an array    \n",
    "            result_list_tex = np.array([x.recv().tolist() for x in pipe_list_tex])\n",
    "            y_pred_flat_tex = result_list_tex.flatten()\n",
    "            y_test_flat_tex = y_test_tex.flatten()\n",
    "\n",
    "            mae_tex, mse_tex, rmse_tex, r2_tex, accuracy_tex, precision_tex, recall_tex, f1_tex, conf_matrix_tex, class_report_tex = calculate_metrics(y_test_flat_tex, y_pred_flat_tex)\n",
    "            print(\"mae:\", mae_tex*100)\n",
    "            print(\"mse:\", mse_tex*100)\n",
    "            print(\"rmse:\", rmse_tex*100)\n",
    "            print(\"r2:\", r2_tex*100)\n",
    "            \n",
    "            print(\"Accuracy:\", accuracy_tex*100)\n",
    "            print(\"Precision:\", precision_tex*100)\n",
    "            print(\"Recall:\", recall_tex*100)\n",
    "            print(\"F1 Score:\", f1_tex*100)\n",
    "            print(\"Confusion Matrix:\\n\", conf_matrix_tex)\n",
    "            print(\"Classification report:\\n\", class_report_tex)\n",
    "\n",
    "            mae_ave_tex.append(mae_tex)\n",
    "            mse_ave_tex.append(mse_tex)\n",
    "            rmse_ave_tex.append(rmse_tex)\n",
    "            r2_ave_tex.append(r2_tex)\n",
    "            \n",
    "            accuracy_ave_tex.append(accuracy_tex)\n",
    "            precision_ave_tex.append(precision_tex)\n",
    "            recall_ave_tex.append(recall_tex)\n",
    "            f1_ave_tex.append(f1_tex)\n",
    "            \n",
    "            # end_time1 = time()\n",
    "            # totalTime1 = convert_seconds_to_minutes(end_time1 - startTime1)\n",
    "            # print(\"Total time 1 is: \", totalTime1)\n",
    "        \n",
    "        '''\n",
    "        Combine K-fold for texture\n",
    "        '''    \n",
    "        k_fold_mae_tex.append(mae_ave_tex)\n",
    "        k_fold_mse_tex.append(mse_ave_tex)\n",
    "        k_fold_rmse_tex.append(rmse_ave_tex)\n",
    "        k_fold_r2_tex.append(r2_ave_tex)\n",
    "        \n",
    "        k_fold_accuracy_tex.append(accuracy_ave_tex)\n",
    "        k_fold_precision_tex.append(precision_ave_tex)\n",
    "        k_fold_recall_tex.append(recall_ave_tex)\n",
    "        k_fold_f1_tex.append(f1_ave_tex) \n",
    "        \n",
    "        '''\n",
    "        Combine values for texture\n",
    "        '''\n",
    "        mae_values_tex.append(average_of_n_values(mae_ave_tex)) \n",
    "        mse_values_tex.append(average_of_n_values(mse_ave_tex)) \n",
    "        rmse_values_tex.append(average_of_n_values(rmse_ave_tex)) \n",
    "        r2_values_tex.append(average_of_n_values(r2_ave_tex)) \n",
    "        \n",
    "        accuracy_values_tex.append(average_of_n_values(accuracy_ave_tex))  \n",
    "        precision_values_tex.append(average_of_n_values(precision_ave_tex)) \n",
    "        recall_values_tex.append(average_of_n_values(recall_ave_tex)) \n",
    "        f1_values_tex.append(average_of_n_values(f1_ave_tex)) \n",
    "\n",
    "        # end_time2 = time()\n",
    "        # totalTime2 = convert_seconds_to_minutes(end_time2 - startTime2)\n",
    "        # print(\"Total time 2 is: \", totalTime2)\n",
    "\n",
    "    '''\n",
    "    Combine values for texture\n",
    "    '''    \n",
    "    mae_values_array_tex.append(mae_values_tex)\n",
    "    mse_values_array_tex.append(mse_values_tex)\n",
    "    rmse_values_array_tex.append(rmse_values_tex)\n",
    "    r2_values_array_tex.append(r2_values_tex)\n",
    "    \n",
    "    accuracy_values_array_tex.append(accuracy_values_tex)\n",
    "    precision_values_array_tex.append(precision_values_tex)\n",
    "    recall_values_array_tex.append(recall_values_tex)\n",
    "    f1_values_array_tex.append(f1_values_tex)    \n",
    "    \n",
    "    # end_time3 = time()\n",
    "    # totalTime3 = convert_seconds_to_minutes(end_time3 - startTime3)\n",
    "    # print(\"Total time 3 is: \", totalTime3)\n",
    "\n",
    "\n",
    "'''\n",
    "Print K-fold for texture\n",
    "'''\n",
    "print(\"These are the tex mae for each k-fold split\", k_fold_mae_tex, \"\\n\")\n",
    "print(\"These are the tex mse for each k-fold split\", k_fold_mse_tex, \"\\n\")\n",
    "print(\"These are the tex rmse for each k-fold split\", k_fold_rmse_tex, \"\\n\")\n",
    "print(\"These are the tex r2 for each k-fold split\", k_fold_r2_tex, \"\\n\")\n",
    "\n",
    "print(\"These are the tex accuracy for each k-fold split\", k_fold_accuracy_tex, \"\\n\")\n",
    "print(\"These are the tex precision for each k-fold split\", k_fold_precision_tex, \"\\n\")\n",
    "print(\"These are the tex recall for each k-fold split\", k_fold_recall_tex, \"\\n\")\n",
    "print(\"These are the tex f1 for each k-fold split\", k_fold_f1_tex, \"\\n\")\n",
    "\n",
    "end_time4 = time()\n",
    "totalTime4 = convert_seconds_to_minutes(end_time4 - startTime4)\n",
    "print(\"Total completion time is: \", totalTime4)\n",
    "\n",
    "'''\n",
    "Plot for texture\n",
    "'''\n",
    "plot_accuracy_bar_graph(mae_values_array_tex, \"mae_texture_plot\", \"mae_texture_plot\")\n",
    "plot_accuracy_bar_graph(mse_values_array_tex, \"mse_texture_plot\", \"mse_texture_plot\")\n",
    "plot_accuracy_bar_graph(rmse_values_array_tex, \"rmse_texture_plot\", \"rmse_texture_plot\")\n",
    "plot_accuracy_bar_graph(r2_values_array_tex, \"r2_texture_plot\", \"r2_texture_plot\")\n",
    "\n",
    "plot_accuracy_bar_graph(accuracy_values_array_tex, \"accuracy_texture_plot\", \"accuracy_texture_plot\")\n",
    "plot_accuracy_bar_graph(precision_values_array_tex, \"precision_texture_plot\", \"precision_texture_plot\")\n",
    "plot_accuracy_bar_graph(recall_values_array_tex, \"recall_texture_plot\", \"recall_texture_plot\")\n",
    "plot_accuracy_bar_graph(f1_values_array_tex, \"f1_texture_plot\", \"f1_texture_plot\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta in theta_values:\n",
    "    \n",
    "    '''\n",
    "    Metric value for deformation\n",
    "    '''\n",
    "    mae_values_def = []\n",
    "    mse_values_def = []\n",
    "    rmse_values_def = []\n",
    "    r2_values_def = []\n",
    "    \n",
    "    accuracy_values_def = []\n",
    "    precision_values_def = []\n",
    "    recall_values_def = []\n",
    "    f1_values_def = []\n",
    "    \n",
    "    '''\n",
    "    Metric value for texture\n",
    "    '''\n",
    "    mae_values_tex = []\n",
    "    mse_values_tex = []\n",
    "    rmse_values_tex = []\n",
    "    r2_values_tex = []\n",
    "    \n",
    "    accuracy_values_tex = []\n",
    "    precision_values_tex = []\n",
    "    recall_values_tex = []\n",
    "    f1_values_tex = []\n",
    "    \n",
    "    for gamma in gamma_values:\n",
    "        \n",
    "        startTime3 = time() # Add a timer. \n",
    "        \n",
    "        '''\n",
    "        Metric ave for deformation\n",
    "        '''\n",
    "        mae_ave_def = []\n",
    "        mse_ave_def = []\n",
    "        rmse_ave_def = []\n",
    "        r2_ave_def = []\n",
    "        \n",
    "        accuracy_ave_def = []\n",
    "        precision_ave_def = []\n",
    "        recall_ave_def = []\n",
    "        f1_ave_def = []\n",
    "    \n",
    "        '''\n",
    "        Metric ave for texture\n",
    "        '''\n",
    "        mae_ave_tex = []\n",
    "        mse_ave_tex = []\n",
    "        rmse_ave_tex = []\n",
    "        r2_ave_tex = []\n",
    "        \n",
    "        accuracy_ave_tex = []\n",
    "        precision_ave_tex = []\n",
    "        recall_ave_tex = []\n",
    "        f1_ave_tex = []\n",
    "        \n",
    "        for fold_no in range(1,n_splits+1):\n",
    "            \n",
    "            startTime2 = time() # Add a timer. \n",
    "            scaler_min_max = MinMaxScaler(feature_range=(0.01, .99))\n",
    "            \n",
    "            '''\n",
    "            Train the deformation data\n",
    "            '''\n",
    "            newtrain_def = pd.read_csv(os.path.join(directory_path_param, 'train_fold_def_' + str(fold_no) + '.csv'))\n",
    "            \n",
    "            newtrain_def = newtrain_def.iloc[:,1:]\n",
    "            new_X_train_def = newtrain_def.iloc[:,:-1].values\n",
    "            new_y_train_def = newtrain_def.iloc[:,-1].values # Assign the label to the last column\n",
    "            \n",
    "            new_X_train_def = scaler_min_max.fit_transform(new_X_train_def)\n",
    "            new_X_train_def = new_X_train_def.T\n",
    "\n",
    "            nn_train_def = ReflexFuzzyNeuroNetwork(gamma=gamma, theta=theta*.1)\n",
    "            nn_train_def.train(new_X_train_def, new_y_train_def)\n",
    "            print(\"Training is Done\")\n",
    "        \n",
    "            '''\n",
    "            Train the texture data\n",
    "            '''\n",
    "            newtrain_tex = pd.read_csv(os.path.join(directory_path_param, 'train_fold_tex_' + str(fold_no) + '.csv'))\n",
    "            \n",
    "            newtrain_tex = newtrain_tex.iloc[:,1:]\n",
    "            new_X_train_tex = newtrain_tex.iloc[:,:-1].values\n",
    "            new_y_train_tex = newtrain_tex.iloc[:,-1].values\n",
    "            \n",
    "            new_X_train_tex = scaler_min_max.fit_transform(new_X_train_tex)\n",
    "            new_X_train_tex = new_X_train_tex.T\n",
    "            \n",
    "            nn_train_tex = ReflexFuzzyNeuroNetwork(gamma=gamma, theta=theta*.1)\n",
    "            nn_train_tex.train(new_X_train_tex, new_y_train_tex)\n",
    "            print(\"Training is Done\")\n",
    "\n",
    "            '''\n",
    "            Start the multiprocessing process for testing deformation.\n",
    "            '''\n",
    "            '''\n",
    "            Test the deformation data\n",
    "            '''\n",
    "            newval_def = pd.read_csv(os.path.join(directory_path_param, 'val_fold_def_' + str(fold_no) + '.csv'))\n",
    "            newval_def = newval_def.iloc[:,1:]\n",
    "        \n",
    "            X_def_newval = newval_def.iloc[:, :4].values\n",
    "            y_def_newval = newval_def.iloc[:, newval_def.shape[1]-1].values\n",
    "            \n",
    "            new_X_val_def = scaler_min_max.fit_transform(X_def_newval)\n",
    "\n",
    "            X_train_def, X_test_def, y_train_def, y_test_def_newval = train_test_split(new_X_val_def, y_def_newval, train_size=1, random_state=42)\n",
    "\n",
    "            num_parts_def = 3950\n",
    "            # num_parts_def = 2634\n",
    "            # num_parts_def = 1580\n",
    "            split_size_def = len(X_test_def) // num_parts_def\n",
    "            x_split_def = []\n",
    "            y_split_def = []\n",
    "            for i in range(num_parts_def):\n",
    "                start_index_def = i * split_size_def\n",
    "                end_index_def = (i + 1) * split_size_def\n",
    "                x_part_def = X_test_def[start_index_def:end_index_def]\n",
    "                y_part_def = y_test_def_newval[start_index_def:end_index_def]\n",
    "                x_split_def.append(x_part_def)\n",
    "                y_split_def.append(y_part_def)\n",
    "            x_split_def = np.array(x_split_def)\n",
    "            y_split_def = np.array(y_split_def)\n",
    "\n",
    "            transposed_arrays_def = []\n",
    "            for i in range(num_parts_def):\n",
    "                transposed_arrays_def.append(x_split_def[i].T)\n",
    "            transposed_arrays_def = np.array(transposed_arrays_def)\n",
    "\n",
    "            '''\n",
    "            Test the texture data\n",
    "            '''\n",
    "            newval_tex = pd.read_csv(os.path.join(directory_path_param, 'val_fold_tex_' + str(fold_no) + '.csv'))\n",
    "            newval_tex = newval_tex.iloc[:,1:]\n",
    "            \n",
    "            X_tex_newval = newval_tex.iloc[:, :-1].values\n",
    "            y_tex_newval = newval_tex.iloc[:, newval_tex.shape[1]-1].values\n",
    "            \n",
    "            new_X_val_tex = scaler_min_max.fit_transform(X_tex_newval)\n",
    "\n",
    "            X_train_tex, X_test_tex, y_train_tex, y_test_tex_newval = train_test_split(new_X_val_tex, y_tex_newval, train_size=1, random_state=42)\n",
    "\n",
    "            num_parts_tex = 3950\n",
    "            # num_parts_tex = 2634\n",
    "            # num_parts_tex = 1580\n",
    "            \n",
    "            split_size_tex = len(new_X_val_tex) // num_parts_tex\n",
    "            x_split_tex = []\n",
    "            y_split_tex = []\n",
    "            for i in range(num_parts_tex):\n",
    "                start_index_tex = i * split_size_tex\n",
    "                end_index_tex = (i + 1) * split_size_tex\n",
    "                x_part_tex = X_test_tex[start_index_tex:end_index_tex]\n",
    "                y_part_tex = y_test_tex_newval[start_index_tex:end_index_tex]\n",
    "                x_split_tex.append(x_part_tex)\n",
    "                y_split_tex.append(y_part_tex)\n",
    "            x_split_tex = np.array(x_split_tex)\n",
    "            y_split_tex = np.array(y_split_tex)\n",
    "\n",
    "            transposed_arrays_tex = []\n",
    "            for i in range(num_parts_tex):\n",
    "                transposed_arrays_tex.append(x_split_tex[i].T)\n",
    "            transposed_arrays_tex = np.array(transposed_arrays_tex)\n",
    "\n",
    "            '''\n",
    "            Get the accuracy for defromation and texture\n",
    "            '''\n",
    "            end_range = 10\n",
    "            \n",
    "            y_test_def = np.array([])\n",
    "            jobs_def = []\n",
    "            pipe_list_def = []\n",
    "\n",
    "            y_test_tex = np.array([])\n",
    "            jobs_tex = []\n",
    "            pipe_list_tex = []     \n",
    "\n",
    "            # for i in range(0, os.cpu_count()):\n",
    "            # for i in range(0, 94):\n",
    "            for i in range(0, end_range):\n",
    "                startTime1 = time() # Add a timer. \n",
    "    \n",
    "                # range(0, os.cpu_count())\n",
    "                recv_end_def, send_end_def = multiprocessing.Pipe(False)\n",
    "                recv_end_tex, send_end_tex = multiprocessing.Pipe(False)\n",
    "                p_def = multiprocessing.Process(target=testAlgo, args=(transposed_arrays_def[i], y_split_def[i], nn_train_def, send_end_def))\n",
    "                p_tex = multiprocessing.Process(target=testAlgo, args=(transposed_arrays_tex[i], y_split_tex[i], nn_train_tex, send_end_tex))\n",
    "            \n",
    "                jobs_def.append(p_def)\n",
    "                pipe_list_def.append(recv_end_def)\n",
    "                p_def.start()\n",
    "\n",
    "                jobs_tex.append(p_tex)\n",
    "                pipe_list_tex.append(recv_end_tex)\n",
    "                p_tex.start()\n",
    "                \n",
    "            # Create a new numpy array the same as y_split_def\n",
    "            for i in range(end_range): \n",
    "                new_elements_def = y_split_def[i]  \n",
    "                y_test_def = np.append(y_test_def, new_elements_def)\n",
    "            y_test_def = y_test_def.reshape((end_range, -1))\n",
    "\n",
    "            # Create a new numpy array the same as y_split_def\n",
    "            for i in range(end_range): \n",
    "                new_elements_tex = y_split_tex[i]  \n",
    "                y_test_tex = np.append(y_test_tex, new_elements_tex)\n",
    "            y_test_tex = y_test_tex.reshape((end_range, -1))\n",
    "\n",
    "            # Join all cores results into one\n",
    "            for proc in jobs_def:\n",
    "                proc.join()\n",
    "\n",
    "            # Join all cores results into one\n",
    "            for proc in jobs_tex:\n",
    "                proc.join()\n",
    "                \n",
    "            '''\n",
    "            Metrics For Deformation\n",
    "            '''\n",
    "            # Putting all cores results into an array    \n",
    "            result_list_def = np.array([x.recv().tolist() for x in pipe_list_def])\n",
    "            y_pred_flat_def = result_list_def.flatten()\n",
    "            y_test_flat_def = y_test_def.flatten()\n",
    "\n",
    "            # # Regression metrices\n",
    "            # mae_def = mean_absolute_error(y_test_flat_def, y_pred_flat_def)\n",
    "            # mse_def = mean_squared_error(y_test_flat_def, y_pred_flat_def)\n",
    "            # rmse_def = np.sqrt(mse_def)\n",
    "            # r2_def = r2_score(y_test_flat_def, y_pred_flat_def)\n",
    "            \n",
    "            # # Classification metrices\n",
    "            # accuracy_def = accuracy_score(y_test_flat_def, y_pred_flat_def)\n",
    "            # precision_def = precision_score(y_test_flat_def, y_pred_flat_def, average='micro')\n",
    "            # recall_def = recall_score(y_test_flat_def, y_pred_flat_def, average='micro')\n",
    "            # f1_def = f1_score(y_test_flat_def, y_pred_flat_def, average='micro')\n",
    "            # conf_matrix_def = confusion_matrix(y_test_flat_def, y_pred_flat_def)\n",
    "            # class_report_def = classification_report(y_test_flat_def, y_pred_flat_def)\n",
    "            \n",
    "            mae_def, mse_def, rmse_def, r2_def, accuracy_def, precision_def, recall_def, f1_def, conf_matrix_def, class_report_def = calculate_metrics(y_test_flat_def, y_pred_flat_def)\n",
    "            print(\"mae:\", mae_def*100)\n",
    "            print(\"mse:\", mse_def*100)\n",
    "            print(\"rmse:\", rmse_def*100)\n",
    "            print(\"r2:\", r2_def*100)\n",
    "            \n",
    "            print(\"Accuracy:\", accuracy_def*100)\n",
    "            print(\"Precision:\", precision_def*100)\n",
    "            print(\"Recall:\", recall_def*100)\n",
    "            print(\"F1 Score:\", f1_def*100)\n",
    "            print(\"Confusion Matrix:\\n\", conf_matrix_def)\n",
    "            print(\"Classification report:\\n\", class_report_def)\n",
    "            \n",
    "            mae_ave_def.append(mae_def)\n",
    "            mse_ave_def.append(mse_def)\n",
    "            rmse_ave_def.append(rmse_def)\n",
    "            r2_ave_def.append(r2_def)\n",
    "            \n",
    "            accuracy_ave_def.append(accuracy_def)\n",
    "            precision_ave_def.append(precision_def)\n",
    "            recall_ave_def.append(recall_def)\n",
    "            f1_ave_def.append(f1_def)\n",
    "                    \n",
    "            '''\n",
    "            Metrics For Texture\n",
    "            '''\n",
    "            # Putting all cores results into an array    \n",
    "            result_list_tex = np.array([x.recv().tolist() for x in pipe_list_tex])\n",
    "            y_pred_flat_tex = result_list_tex.flatten()\n",
    "            y_test_flat_tex = y_test_tex.flatten()\n",
    "        \n",
    "            # Regression metrices\n",
    "            # mae_tex = mean_absolute_error(y_test_flat_tex, y_pred_flat_tex)\n",
    "            # mse_tex = mean_squared_error(y_test_flat_tex, y_pred_flat_tex)\n",
    "            # rmse_tex = np.sqrt(mse_tex)\n",
    "            # r2_tex = r2_score(y_test_flat_tex, y_pred_flat_tex)\n",
    "            \n",
    "            # # Classification metrices\n",
    "            # accuracy_tex = accuracy_score(y_test_flat_tex, y_pred_flat_tex)\n",
    "            # precision_tex = precision_score(y_test_flat_tex, y_pred_flat_tex, average='micro')\n",
    "            # recall_tex = recall_score(y_test_flat_tex, y_pred_flat_tex, average='micro')\n",
    "            # f1_tex = f1_score(y_test_flat_tex, y_pred_flat_tex, average='micro')\n",
    "            # conf_matrix_tex = confusion_matrix(y_test_flat_tex, y_pred_flat_tex)\n",
    "            # class_report_tex = classification_report(y_test_flat_tex, y_pred_flat_tex)\n",
    "\n",
    "            mae_tex, mse_tex, rmse_tex, r2_tex, accuracy_tex, precision_tex, recall_tex, f1_tex, conf_matrix_tex, class_report_tex = calculate_metrics(y_test_flat_tex, y_pred_flat_tex)\n",
    "            print(\"mae:\", mae_tex*100)\n",
    "            print(\"mse:\", mse_tex*100)\n",
    "            print(\"rmse:\", rmse_tex*100)\n",
    "            print(\"r2:\", r2_tex*100)\n",
    "            \n",
    "            print(\"Accuracy:\", accuracy_tex*100)\n",
    "            print(\"Precision:\", precision_tex*100)\n",
    "            print(\"Recall:\", recall_tex*100)\n",
    "            print(\"F1 Score:\", f1_tex*100)\n",
    "            print(\"Confusion Matrix:\\n\", conf_matrix_tex)\n",
    "            print(\"Classification report:\\n\", class_report_tex)\n",
    "\n",
    "            mae_ave_tex.append(mae_tex)\n",
    "            mse_ave_tex.append(mse_tex)\n",
    "            rmse_ave_tex.append(rmse_tex)\n",
    "            r2_ave_tex.append(r2_tex)\n",
    "            \n",
    "            accuracy_ave_tex.append(accuracy_tex)\n",
    "            precision_ave_tex.append(precision_tex)\n",
    "            recall_ave_tex.append(recall_tex)\n",
    "            f1_ave_tex.append(f1_tex)\n",
    "            \n",
    "            # end_time1 = time()\n",
    "            # totalTime1 = convert_seconds_to_minutes(end_time1 - startTime1)\n",
    "            # print(\"Total time 1 is: \", totalTime1)\n",
    "        \n",
    "        '''\n",
    "        Combine K-fold for deformation\n",
    "        '''\n",
    "        k_fold_mae_def.append(mae_ave_def)\n",
    "        k_fold_mse_def.append(mse_ave_def)\n",
    "        k_fold_rmse_def.append(rmse_ave_def)\n",
    "        k_fold_r2_def.append(r2_ave_def)\n",
    "        \n",
    "        k_fold_accuracy_def.append(accuracy_ave_def)\n",
    "        k_fold_precision_def.append(precision_ave_def)\n",
    "        k_fold_recall_def.append(recall_ave_def)\n",
    "        k_fold_f1_def.append(f1_ave_def)\n",
    "        \n",
    "        '''\n",
    "        Combine K-fold for texture\n",
    "        '''    \n",
    "        k_fold_mae_tex.append(mae_ave_tex)\n",
    "        k_fold_mse_tex.append(mse_ave_tex)\n",
    "        k_fold_rmse_tex.append(rmse_ave_tex)\n",
    "        k_fold_r2_tex.append(r2_ave_tex)\n",
    "        \n",
    "        k_fold_accuracy_tex.append(accuracy_ave_tex)\n",
    "        k_fold_precision_tex.append(precision_ave_tex)\n",
    "        k_fold_recall_tex.append(recall_ave_tex)\n",
    "        k_fold_f1_tex.append(f1_ave_tex) \n",
    "        \n",
    "        '''\n",
    "        Combine values for deformation\n",
    "        '''\n",
    "        mae_values_def.append(average_of_n_values(mae_ave_def)) \n",
    "        mse_values_def.append(average_of_n_values(mse_ave_def)) \n",
    "        rmse_values_def.append(average_of_n_values(rmse_ave_def)) \n",
    "        r2_values_def.append(average_of_n_values(r2_ave_def)) \n",
    "        \n",
    "        accuracy_values_def.append(average_of_n_values(accuracy_ave_def))  \n",
    "        precision_values_def.append(average_of_n_values(precision_ave_def)) \n",
    "        recall_values_def.append(average_of_n_values(recall_ave_def)) \n",
    "        f1_values_def.append(average_of_n_values(f1_ave_def)) \n",
    "\n",
    "        '''\n",
    "        Combine values for texture\n",
    "        '''\n",
    "        mae_values_tex.append(average_of_n_values(mae_ave_tex)) \n",
    "        mse_values_tex.append(average_of_n_values(mse_ave_tex)) \n",
    "        rmse_values_tex.append(average_of_n_values(rmse_ave_tex)) \n",
    "        r2_values_tex.append(average_of_n_values(r2_ave_tex)) \n",
    "        \n",
    "        accuracy_values_tex.append(average_of_n_values(accuracy_ave_tex))  \n",
    "        precision_values_tex.append(average_of_n_values(precision_ave_tex)) \n",
    "        recall_values_tex.append(average_of_n_values(recall_ave_tex)) \n",
    "        f1_values_tex.append(average_of_n_values(f1_ave_tex)) \n",
    "\n",
    "        # end_time2 = time()\n",
    "        # totalTime2 = convert_seconds_to_minutes(end_time2 - startTime2)\n",
    "        # print(\"Total time 2 is: \", totalTime2)\n",
    "\n",
    "    '''\n",
    "    Combine values for deformation\n",
    "    '''\n",
    "    mae_values_array_def.append(mae_values_def)\n",
    "    mse_values_array_def.append(mse_values_def)\n",
    "    rmse_values_array_def.append(rmse_values_def)\n",
    "    r2_values_array_def.append(r2_values_def)\n",
    "    \n",
    "    accuracy_values_array_def.append(accuracy_values_def)\n",
    "    precision_values_array_def.append(precision_values_def)\n",
    "    recall_values_array_def.append(recall_values_def)\n",
    "    f1_values_array_def.append(f1_values_def)\n",
    "    \n",
    "    '''\n",
    "    Combine values for texture\n",
    "    '''    \n",
    "    mae_values_array_tex.append(mae_values_tex)\n",
    "    mse_values_array_tex.append(mse_values_tex)\n",
    "    rmse_values_array_tex.append(rmse_values_tex)\n",
    "    r2_values_array_tex.append(r2_values_tex)\n",
    "    \n",
    "    accuracy_values_array_tex.append(accuracy_values_tex)\n",
    "    precision_values_array_tex.append(precision_values_tex)\n",
    "    recall_values_array_tex.append(recall_values_tex)\n",
    "    f1_values_array_tex.append(f1_values_tex)    \n",
    "    \n",
    "    # end_time3 = time()\n",
    "    # totalTime3 = convert_seconds_to_minutes(end_time3 - startTime3)\n",
    "    # print(\"Total time 3 is: \", totalTime3)\n",
    "\n",
    "'''\n",
    "Print K-fold for deformation\n",
    "'''\n",
    "print(\"These are the def mae for each k-fold split\", k_fold_mae_def, \"\\n\")\n",
    "print(\"These are the def mse for each k-fold split\", k_fold_mse_def, \"\\n\")\n",
    "print(\"These are the def rmse for each k-fold split\", k_fold_rmse_def, \"\\n\")\n",
    "print(\"These are the def r2 for each k-fold split\", k_fold_r2_def, \"\\n\")\n",
    "\n",
    "print(\"These are the def accuracy for each k-fold split\", k_fold_accuracy_def, \"\\n\")\n",
    "print(\"These are the def precision for each k-fold split\", k_fold_precision_def, \"\\n\")\n",
    "print(\"These are the def recall for each k-fold split\", k_fold_recall_def, \"\\n\")\n",
    "print(\"These are the def f1 for each k-fold split\", k_fold_f1_def, \"\\n\")\n",
    "\n",
    "'''\n",
    "Print K-fold for texture\n",
    "'''\n",
    "print(\"These are the tex mae for each k-fold split\", k_fold_mae_tex, \"\\n\")\n",
    "print(\"These are the tex mse for each k-fold split\", k_fold_mse_tex, \"\\n\")\n",
    "print(\"These are the tex rmse for each k-fold split\", k_fold_rmse_tex, \"\\n\")\n",
    "print(\"These are the tex r2 for each k-fold split\", k_fold_r2_tex, \"\\n\")\n",
    "\n",
    "print(\"These are the tex accuracy for each k-fold split\", k_fold_accuracy_tex, \"\\n\")\n",
    "print(\"These are the tex precision for each k-fold split\", k_fold_precision_tex, \"\\n\")\n",
    "print(\"These are the tex recall for each k-fold split\", k_fold_recall_tex, \"\\n\")\n",
    "print(\"These are the tex f1 for each k-fold split\", k_fold_f1_tex, \"\\n\")\n",
    "\n",
    "end_time4 = time()\n",
    "totalTime4 = convert_seconds_to_minutes(end_time4 - startTime4)\n",
    "print(\"Total completion time is: \", totalTime4)\n",
    "\n",
    "'''\n",
    "Plot for deformation\n",
    "'''\n",
    "plot_accuracy_bar_graph(mae_values_array_def, \"mae_deformation_plot\", \"mae_deformation_plot\")\n",
    "plot_accuracy_bar_graph(mse_values_array_def, \"mse_deformation_plot\", \"mse_deformation_plot\")\n",
    "plot_accuracy_bar_graph(rmse_values_array_def, \"rmse_deformation_plot\", \"rmse_deformation_plot\")\n",
    "plot_accuracy_bar_graph(r2_values_array_def, \"r2_deformation_plot\", \"r2_deformation_plot\")\n",
    "\n",
    "plot_accuracy_bar_graph(accuracy_values_array_def, \"accuracy_deformation_plot\", \"accuracy_deformation_plot\")\n",
    "plot_accuracy_bar_graph(precision_values_array_def, \"precision_deformation_plot\", \"precision_deformation_plot\")\n",
    "plot_accuracy_bar_graph(recall_values_array_def, \"recall_deformation_plot\", \"recall_deformation_plot\")\n",
    "plot_accuracy_bar_graph(f1_values_array_def, \"f1_deformation_plot\", \"f1_deformation_plot\")\n",
    "\n",
    "'''\n",
    "Plot for texture\n",
    "'''\n",
    "plot_accuracy_bar_graph(mae_values_array_tex, \"mae_texture_plot\", \"mae_texture_plot\")\n",
    "plot_accuracy_bar_graph(mse_values_array_tex, \"mse_texture_plot\", \"mse_texture_plot\")\n",
    "plot_accuracy_bar_graph(rmse_values_array_tex, \"rmse_texture_plot\", \"rmse_texture_plot\")\n",
    "plot_accuracy_bar_graph(r2_values_array_tex, \"r2_texture_plot\", \"r2_texture_plot\")\n",
    "\n",
    "plot_accuracy_bar_graph(accuracy_values_array_tex, \"accuracy_texture_plot\", \"accuracy_texture_plot\")\n",
    "plot_accuracy_bar_graph(precision_values_array_tex, \"precision_texture_plot\", \"precision_texture_plot\")\n",
    "plot_accuracy_bar_graph(recall_values_array_tex, \"recall_texture_plot\", \"recall_texture_plot\")\n",
    "plot_accuracy_bar_graph(f1_values_array_tex, \"f1_texture_plot\", \"f1_texture_plot\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
